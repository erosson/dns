the big tf hosting migration checklist

this doc is just a shortcut. authoritative source: /public/dns/domains/*

docker hosting todo:
* [x] docker image autobuilds on ghcr.io
  * [x] individual sites
  * [x] combined site
* [x] configure docker-* subdomain prefix, for testing
* [x] create test page, with healthcheck and links to each domain
* [x] create cloudflare dns entries in tf
* [x] investigate possible hosts
  * [~] aws: no ghcr support and painful auth
  * [x] digitalocean: works okay, but I wish they wouldn't try to handle https
  * [~] linode
  * [~] others???
* [x] create digitalocean (or other) hosting via tf, not by hand
  * [x] digitalocean env config (it handles https): DOMAIN_SUFFIX=:80 ; DOMAIN_PREFIX=http://
  * [x] domain config, too. test with docker-* prefix
* [x] digitalocean: separate finsat billing and my personal billing
* [x] digitalocean: full redeploy on push (redeploys are currently manual)
  * [x] are we using digitalocean, or linode, or something else? (aws is too complicated)
  * [x] digitalocean auth -> infisical
  * [x] digitalocean auth: tf -> github-actions. can tf create a deploy-specific token? or only reuse the current auth?
* [x] trigger combined site build when child site packages change
* [ ] automated smoke testing (before swarmsim goes to production!)


---

!: running at docker-HOSTNAME, not HOSTNAME. ready to run when legacy stuff removed and new domains added
x: completely done

erosson.org:
* [!] cooking.erosson.org
* [!] freecbt.erosson.org
* [x] test-tf.erosson.org
* [!] vegas-wordle.erosson.org
* [ ] www.erosson.org (partial - https://cf-www.erosson.org/ exists. blocked on cf-piano.erosson.org; no cf monorepo support!)
* [x] @.erosson.org

swarmsim.com:
* [!] math2.swarmsim.com
* [x] math.swarmsim.com
* [ ] elm.swarmsim.com
* [ ] 2023.swarmsim.com
* [!] www.swarmsim.com
* [!] preprod.swarmsim.com
* [x] @.swarmsim.com

misc:
* [!] www.zealgame.com
* [x] @.zealgame.com
* [ ] www.x-marked.com
* [-] www.warswarms.com (this is non-static, hosted on firebase)
* [x] www.war-swarms.com redirect
* [x] www.warswarm.com redirect
* [x] www.erosson.com redirect
* [x] www.swarmsimulator.com redirect
* [x] www.erosson.us
* [x] www.evanrosson.com
* [x] www.evanrosson.org
* [x] www.xmarkedgame.com

---

possible alternate strategy: one docker image, configured with caddy + all my static hosted stuff. rebuild+redeploy image when any of my sites change.
I really like this one - caddy will last longer than a third party service.
* each site builds static files, a caddyfile, and a docker image
* after push, rebuild the docker image, then trigger combined repo build (but I'd really rather handle the trigger in the combined repo, not the child repo!)
* combined repo builds a combined static-sites docker image, from multi-stage builds and individual images. a new site is a couple lines in the combined dockerfile

---

hosting strategies, general

* self-hosted, caddy + static files
    * zero vendor lock-in
    * occasional downtime likely (cloudflare should somewhat mitigate this?)
    * educational
    * harder deployment, mostly - build machine needs deploy credentials
    * redirects are easy
* cloud static site hosting
    * all the vendor lock-in (I'm okay with lock-in for S3, less so for netlify/cloudflare-pages)
    * downtime is unlikely
    * easier deployment, mostly - comes with a build machine
    * redirects are painful

---

hosting strategies

* github + cloudflare-pages
    * we're subject to cloudflare-pages artificial limitations, like no monorepos
    * every new project requires infra configuration
* docker + caddy per-project
    * relatively easy to build, test
    * every new project requires infra configuration
* one big docker + caddy image, rebuilt on change
    * no need for project-specific infra config!
    * ...instead, the problem is CI config. how to rebuild the image when something changes? constantly git-pull...?
* one big docker + caddy image, pulls latest from git
    * no need for project-specific infra config!
    * solves CI config
    * production needs our github credentials? not ideal
* one big docker + caddy image, a second build image that periodically pulls the latest from git and pushes a new image
    * no need for project-specific infra config!
    * no need for production to have source credentials!
    * surely there's already a tool for this. building it myself seems silly. but I don't know the tool. argocd? but kubernetes is needlessly complex.
    * an image for building the image seems complicated.